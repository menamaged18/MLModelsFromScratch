{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8ucNh8Wh4jx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import inspect # to prvent using private methods in class"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementing NN output with one hidden layer"
      ],
      "metadata": {
        "id": "DeS5J8TPiRAb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(Z):\n",
        "  return (1/(1 + np.exp(-Z)))"
      ],
      "metadata": {
        "id": "G4Ovy9V7iU3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Compute_Z(X, W, B):\n",
        "  z = np.dot(X, W) + B\n",
        "  return z"
      ],
      "metadata": {
        "id": "OD3Iw0i2iXvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def OneHiddenLayerNN(X,W1,B1,W2,B2):\n",
        "  Z1 = Compute_Z(X,W1,B1)\n",
        "  A1 = sigmoid(Z1)\n",
        "  Z2 = Compute_Z(A1,W2,B2)\n",
        "  A2 = sigmoid(Z2)\n",
        "  return A2"
      ],
      "metadata": {
        "id": "VD2KIX03iaJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "implement gradient descent for neural network with one hidden layer\n",
        "\n",
        "and for now assume that we're doing binary classification so the cost will be\n",
        "(y_hat - y)**2\n",
        "\n",
        "note that:\n",
        "\n",
        "\n",
        "*   y_hat is A2\n",
        "*   keepdims = true in mumpy make sure that the result will not be (n,) it will be (n, m)\n",
        "\n",
        "*   g' refers to the drevative of the activation function\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "50OZxWQJHT3q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def NNGDFor1HiddenUnit(X, Y, W1, B1, W2, B2, alpha, iter_number):\n",
        "  num_samples, num_features = X.shape\n",
        "  for iter in range(iter_number):\n",
        "    A1 = sigmoid(Compute_Z(X,W1,B1))\n",
        "    A2 = OneHiddenLayerNN(X,W1,B1,W2,B2)\n",
        "\n",
        "    DZ2 = A2 - Y\n",
        "    DW2 = (1/num_samples) * np.dot(A1.T,DZ2)\n",
        "    DB2 = (1/num_samples) * np.sum(DZ2,axis=1,keepdims=True)\n",
        "    DZ1 = np.dot(DZ2,W2.T) * (A1 * (1 - A1))\n",
        "    DW1 = (1/num_samples) * np.dot(X.T,DZ1)\n",
        "    DB1 = (1/num_samples) * np.sum(DZ1,axis=1,keepdims=True)\n",
        "\n",
        "    W1 = W1 - alpha * DW1\n",
        "    W2 = W2 - alpha * DW2\n",
        "    B1 = B1 - alpha * DB1\n",
        "    B2 = B2 - alpha * DB2\n",
        "\n",
        "  return W1, W2, B1, B2"
      ],
      "metadata": {
        "id": "hP2CJXCfHTj2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example:"
      ],
      "metadata": {
        "id": "9iujXo9Y3BSG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage:\n",
        "input_size = 2\n",
        "hidden_size = 4\n",
        "output_size = 1\n",
        "# Initialize weights and biases\n",
        "W1 = np.random.uniform(size=(input_size, hidden_size))\n",
        "B1 = np.random.uniform(size=(1, hidden_size))\n",
        "W2 = np.random.uniform(size=(hidden_size, output_size))\n",
        "B2 = np.random.uniform(size=(1, output_size))\n",
        "\n",
        "X = np.array([[0.1, 0.2], [0.3, 0.4]])\n",
        "Y = np.array([[0.5], [0.7]])\n",
        "W1_new, W2_new, b1_new, b2_new = NNGDFor1HiddenUnit(X, Y, W1, B1, W2, B2, 0.1, 1000)\n",
        "\n",
        "output = OneHiddenLayerNN(X,W1_new,b1_new,W2_new,b2_new)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0udiAmqb3FpG",
        "outputId": "e4f3e34e-1e9b-4b90-8efa-1d20413a9b23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.5000008 ]\n",
            " [0.69999925]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# better implementation"
      ],
      "metadata": {
        "id": "gprrCj1pXJPi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class OneHiddenLayerNN:\n",
        "    def __init__(self,input_size, hidden_size, output_size, alpha):\n",
        "        self.W1 = np.random.uniform(size=(input_size, hidden_size))\n",
        "        self.B1 = np.random.uniform(size=(1, hidden_size))\n",
        "        self.W2 = np.random.uniform(size=(hidden_size, output_size))\n",
        "        self.B2 = np.random.uniform(size=(1, output_size))\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def sigmoid(self, Z):\n",
        "        return 1 / (1 + np.exp(-Z))\n",
        "\n",
        "    def compute_Z(self, X, W, B):\n",
        "        return np.dot(X, W) + B\n",
        "\n",
        "    def forward_propagation(self, X):\n",
        "        Z1 = self.compute_Z(X, self.W1, self.B1)\n",
        "        A1 = self.sigmoid(Z1)\n",
        "        Z2 = self.compute_Z(A1, self.W2, self.B2)\n",
        "        A2 = self.sigmoid(Z2)\n",
        "        return A1, A2\n",
        "\n",
        "    def train(self, X, Y, iter_number):\n",
        "        num_samples, num_features = X.shape\n",
        "\n",
        "        for iter in range(iter_number):\n",
        "            A1, A2 = self.forward_propagation(X)\n",
        "            print(A2.shape)\n",
        "            print(Y.shape)\n",
        "            DZ2 = A2 - Y\n",
        "            print(\"DZ2 shape is:\",DZ2.shape)\n",
        "            DW2 = (1 / num_samples) * np.dot(A1.T, DZ2)\n",
        "            DB2 = (1 / num_samples) * np.sum(DZ2, axis=0, keepdims=True)\n",
        "            DZ1 = np.dot(DZ2, self.W2.T) * (A1 * (1 - A1))\n",
        "            DW1 = (1 / num_samples) * np.dot(X.T, DZ1)\n",
        "            DB1 = (1 / num_samples) * np.sum(DZ1, axis=0, keepdims=True)\n",
        "\n",
        "            self.W1 -= self.alpha * DW1\n",
        "            self.W2 -= self.alpha * DW2\n",
        "            self.B1 -= self.alpha * DB1\n",
        "            self.B2 -= self.alpha * DB2\n",
        "\n",
        "        return self.W1, self.W2, self.B1, self.B2\n"
      ],
      "metadata": {
        "id": "rn5Js5EVZs_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Example usage:\n",
        "input_size = 2\n",
        "hidden_size = 4\n",
        "output_size = 1\n",
        "\n",
        "X2 = np.array([[0.1, 0.2], [0.3, 0.4], [0.5, 0.7]])\n",
        "Y2 = np.array([[0.5], [0.7], [0.9]])\n",
        "nn2 = OneHiddenLayerNN(input_size, hidden_size, output_size, 2)\n",
        "W1_new2, W2_new2, b1_new2, b2_new2 = nn2.train(X2, Y2, 1)\n",
        "A1, A2 = nn2.forward_propagation(X2)\n",
        "print(\"predicted:\" , A2)\n",
        "print(\"actual:\" , Y2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfiH5VuQf4Vt",
        "outputId": "2b797128-3812-4403-8e5d-2b9c9f8d53d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 1)\n",
            "(3, 1)\n",
            "DZ2 shape is: (3, 1)\n",
            "predicted: [[0.75961034]\n",
            " [0.77386876]\n",
            " [0.78940534]]\n",
            "actual: [[0.5]\n",
            " [0.7]\n",
            " [0.9]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "to prevent using private methods"
      ],
      "metadata": {
        "id": "2Tm7nHyi_NAx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def private_method(method):\n",
        "    def wrapper(self, *args, **kwargs):\n",
        "        stack = inspect.stack()\n",
        "        # Check if the caller is a method of the same class\n",
        "        if stack[1].function not in dir(self):\n",
        "            raise AttributeError(f\"{method.__name__} is a private method.\")\n",
        "        return method(self, *args, **kwargs)\n",
        "    return wrapper\n",
        "# this will make that move: \"obj._MyClass__private_method()\"  # raise an AttributeError"
      ],
      "metadata": {
        "id": "lbwfYojh_RQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep L Neural Networks"
      ],
      "metadata": {
        "id": "dcHog4vpiOFa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DeepNNOneOutput:\n",
        "    def __init__(self, DNN_Layers, alpha):\n",
        "        self.W = []\n",
        "        self.B = []\n",
        "        self.costHistory = []\n",
        "        self.DNN_Layers = DNN_Layers\n",
        "        self.alpha = alpha\n",
        "\n",
        "    # helper functions\n",
        "    def __initWeights(self,X):\n",
        "        X_size = X.shape[1]\n",
        "        for i in range(len(self.DNN_Layers)):\n",
        "            if i == 0:\n",
        "                self.W.append(np.random.uniform(size=(X_size, self.DNN_Layers[i])))\n",
        "                self.B.append(np.random.uniform(size=(1, self.DNN_Layers[i])))\n",
        "            else:\n",
        "                self.W.append(np.random.uniform(size=(self.DNN_Layers[i-1],self.DNN_Layers[i])))\n",
        "                self.B.append(np.random.uniform(size=(1, self.DNN_Layers[i])))\n",
        "            # print(self.W[i].shape)\n",
        "\n",
        "    def __sigmoid(self, Z):\n",
        "        return 1 / (1 + np.exp(-Z))\n",
        "\n",
        "    def __compute_Z(self, X, W, B):\n",
        "        return np.dot(X, W) + B\n",
        "\n",
        "    def __compute_cost(self, Y, Y_hat):\n",
        "        m = Y.shape[1]\n",
        "        cost = -(1 / m) * np.sum(Y * np.log(Y_hat) + (1 - Y) * np.log(1 - Y_hat))\n",
        "        return np.squeeze(cost) # np.squeeze used to transform the result from (1, 1) ig.[[5]] to () ig. 5\n",
        "\n",
        "    def forward_propagation(self, X):\n",
        "        # intialize the weights\n",
        "        if not self.W:\n",
        "            self.__initWeights(X)\n",
        "        # to store every layer output\n",
        "        A = [X] # Initialize A with the input X\n",
        "        for i in range(len(self.DNN_Layers)):\n",
        "            Z = self.__compute_Z(A[i], self.W[i], self.B[i])\n",
        "            A.append(self.__sigmoid(Z))\n",
        "        return A[1:] # Return the outputs of all layers except the input\n",
        "\n",
        "    def train(self, X, Y, iter_number):\n",
        "        num_samples, num_features = X.shape\n",
        "\n",
        "        for iter in range(iter_number):\n",
        "          A = self.forward_propagation(X)\n",
        "          if iter % 100 == 0:\n",
        "              cost = self.__compute_cost(Y, A[-1])\n",
        "              self.costHistory.append(cost)\n",
        "\n",
        "          # Backpropagation\n",
        "          DA = A[-1] - Y\n",
        "          # print(\"A[-1] shape is: \" ,A[-1].shape)\n",
        "          # print(\"Y shape is: \" ,Y.shape)\n",
        "          # print(\"DA shape is: \",DA.shape)\n",
        "          for i in reversed(range(len(self.DNN_Layers))):\n",
        "            # print(\"A[i] shape is:\",A[i].shape)\n",
        "            DZ = DA * (A[i] * (1 - A[i]))\n",
        "            DW = (1 / num_samples) * np.dot(A[i-1].T, DZ )\n",
        "            DB = (1 / num_samples) * np.sum(DZ, axis=0, keepdims=True)\n",
        "            if i != 0:\n",
        "                DA = np.dot(DZ, self.W[i].T)\n",
        "            self.W[i] -= self.alpha * DW\n",
        "            self.B[i] -= self.alpha * DB\n",
        "\n",
        "    def predict(self, X):\n",
        "        A = self.forward_propagation(X)\n",
        "        Y_hat = A[-1]\n",
        "        predictions = (Y_hat > 0.5).astype(int)  # Convert probabilities to binary output\n",
        "        return predictions\n",
        "\n",
        "    def accuracy(self, X, Y):\n",
        "        predictions = self.predict(X)\n",
        "        accuracy = np.mean(predictions == Y)\n",
        "        return accuracy"
      ],
      "metadata": {
        "id": "C3tMqz50ifGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Example usage:\n",
        "# DNN_Layers = [5, 5, 3, 1] #overfit\n",
        "DNN_Layers = [5,1]\n",
        "X2 = np.array([[0.1, 0.2, 0.2], [0.3, 0.4, 0.3], [0.5, 0.7, 0.6],[0.8, 0.9, 0.7]])\n",
        "Y2 = np.array([[0.5], [0.7], [0.8], [0.9]])\n",
        "print(X2.shape)\n",
        "print(Y2.shape)\n",
        "hnn = DeepNNOneOutput(DNN_Layers, 10)\n",
        "hnn.train(X2, Y2, 1000)\n",
        "A2 = hnn.predict(X2)\n",
        "print(A2)\n",
        "# print(hnn.costHistory)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsZoHiERpcOS",
        "outputId": "8df8cf15-11a1-4ff5-ed95-84a0f734c51c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, 3)\n",
            "(4, 1)\n",
            "[[0.50936711]\n",
            " [0.67876348]\n",
            " [0.82628345]\n",
            " [0.88636923]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "testing on a imdb dataset"
      ],
      "metadata": {
        "id": "jZgzBfmIy2wS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import imdb\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "_cQshCh1y1-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = imdb.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQKCBuBq9ugc",
        "outputId": "44d8d35c-ef1a-4a3d-8b17-b9d39e7d7f16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17464789/17464789 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "max_length = 500\n",
        "x_train_padded = pad_sequences(x_train, maxlen=max_length)\n",
        "x_test_padded = pad_sequences(x_test, maxlen=max_length)\n",
        "\n",
        "# Reshape the labels\n",
        "y_train_reshaped = np.array(y_train).reshape(-1, 1)\n",
        "y_test_reshaped = np.array(y_test).reshape(-1, 1)\n",
        "\n",
        "# Check the shapes\n",
        "print(x_train_padded.shape)  # Expected: (25000, 500)\n",
        "print(y_train_reshaped.shape)  # Expected: (25000, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5EJIPqD91n1d",
        "outputId": "ecf03241-877c-478a-b442-b0fb7a63da09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(25000,)\n",
            "(25000,)\n",
            "(25000, 500)\n",
            "(25000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMDB_DNN_Layers = [50,1]\n",
        "hnn_imdb = DeepNNOneOutput(IMDB_DNN_Layers, 10)\n",
        "hnn_imdb.train(x_train_padded, y_train_reshaped, 1000)\n",
        "print(hnn_imdb.costHistory)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OG7AifYE2xMS",
        "outputId": "ee948605-b524-4685-bff9-7f19b8e48b8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[320452.6722720695, 320452.6722720695, 320452.6722720695, 320452.6722720695, 320452.6722720695, 320452.6722720695, 320452.6722720695, 320452.6722720695, 320452.6722720695, 320452.6722720695]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMDB_ACC = hnn_imdb.accuracy(x_test_padded, y_test_reshaped)\n",
        "print(IMDB_ACC)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-s6ei5BDqze",
        "outputId": "7a140d21-a60b-47dc-f5dd-87731fe62b59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMDB_DNN_Layers = [50, 25, 1]\n",
        "hnn_imdb_model2 = DeepNNOneOutput(IMDB_DNN_Layers, 10)\n",
        "hnn_imdb_model2.train(x_train_padded, y_train_reshaped, 1000)\n",
        "IMDB_ACC_2 = hnn_imdb_model2.accuracy(x_test_padded, y_test_reshaped)\n",
        "print(IMDB_ACC_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtUXvnLSGVe4",
        "outputId": "2ebd88ac-5fbd-484f-a23d-416f6c0a2216"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMDB_DNN_Layers = [50, 25, 1]\n",
        "hnn_imdb_model3 = DeepNNOneOutput(IMDB_DNN_Layers, 0.1)\n",
        "hnn_imdb_model3.train(x_train_padded, y_train_reshaped, 1000)\n",
        "IMDB_ACC_3 = hnn_imdb_model3.accuracy(x_test_padded, y_test_reshaped)\n",
        "print(IMDB_ACC_3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_dtkpuEHwxK",
        "outputId": "a2ca4e78-74bf-4cb2-a748-d62c6aa6f39d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "normalizing the data"
      ],
      "metadata": {
        "id": "fh6a6ziFKoQS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "xTrain_normalized = scaler.fit_transform(x_train_padded)\n",
        "xTest_normalized = scaler.fit_transform(x_test_padded)"
      ],
      "metadata": {
        "id": "Fn0DfvjcKn3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMDB_DNN_Layers = [100, 50, 25, 1]\n",
        "hnn_imdb_model4 = DeepNNOneOutput(IMDB_DNN_Layers, 0.01)\n",
        "hnn_imdb_model4.train(xTrain_normalized, y_train_reshaped, 1000)\n",
        "IMDB_ACC_4 = hnn_imdb_model4.accuracy(xTest_normalized, y_test_reshaped)\n",
        "print(IMDB_ACC_4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JucUyH2DK66A",
        "outputId": "5305c02b-c841-4942-e03d-54af043bc39e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Changing in the structure of DeepNN Class"
      ],
      "metadata": {
        "id": "E69MeUSSJbq0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DeepNNONEOUT:\n",
        "    def __init__(self, DNN_Layers, alpha, threshold):\n",
        "        self.W = []\n",
        "        self.B = []\n",
        "        self.costHistory = []\n",
        "        self.threshold = threshold\n",
        "        self.DNN_Layers = DNN_Layers\n",
        "        self.alpha = alpha\n",
        "\n",
        "    # Helper functions\n",
        "    def __initWeights(self, X):\n",
        "        np.random.seed(1)\n",
        "        X_size = X.shape[1]\n",
        "        for i in range(len(self.DNN_Layers)):\n",
        "            if i == 0:\n",
        "                self.W.append(np.random.randn(X_size, self.DNN_Layers[i]) )\n",
        "                self.B.append(np.zeros((1, self.DNN_Layers[i])))\n",
        "            else:\n",
        "                self.W.append(np.random.randn(self.DNN_Layers[i-1], self.DNN_Layers[i]))\n",
        "                self.B.append(np.zeros((1, self.DNN_Layers[i])))\n",
        "\n",
        "    def __sigmoid(self, Z):\n",
        "        Z = np.clip(Z, -500, 500)  # Clipping values for numerical stability\n",
        "        return 1 / (1 + np.exp(-Z))\n",
        "\n",
        "    def __compute_Z(self, X, W, B):\n",
        "        return np.dot(X, W) + B\n",
        "\n",
        "    def __compute_cost(self, Y, Y_hat):\n",
        "        m = Y.shape[0]\n",
        "        cost = -(1 / m) * np.sum(Y * np.log(Y_hat) + (1 - Y) * np.log(1 - Y_hat))\n",
        "        return np.squeeze(cost)\n",
        "\n",
        "    def forward_propagation(self, X):\n",
        "        A = [X]\n",
        "        for i in range(len(self.DNN_Layers)):\n",
        "            Z = self.__compute_Z(A[i], self.W[i], self.B[i])\n",
        "            A.append(self.__sigmoid(Z))\n",
        "        return A\n",
        "\n",
        "    def train(self, X, Y, iter_number):\n",
        "        if not self.W:\n",
        "            self.__initWeights(X)\n",
        "\n",
        "        num_samples = X.shape[0]\n",
        "\n",
        "        for iter in range(iter_number):\n",
        "            A = self.forward_propagation(X)\n",
        "            if iter % 100 == 0:\n",
        "                cost = self.__compute_cost(Y, A[-1])\n",
        "                self.costHistory.append(cost)\n",
        "\n",
        "            # Backpropagation\n",
        "            DA = A[-1] - Y\n",
        "            for i in reversed(range(len(self.DNN_Layers))):\n",
        "                DZ = DA * (A[i+1] * (1 - A[i+1]))\n",
        "                DW = (1 / num_samples) * np.dot(A[i].T, DZ)\n",
        "                DB = (1 / num_samples) * np.sum(DZ, axis=0, keepdims=True)\n",
        "                if i != 0:\n",
        "                    DA = np.dot(DZ, self.W[i].T)\n",
        "\n",
        "                self.W[i] -= self.alpha * DW\n",
        "                self.B[i] -= self.alpha * DB\n",
        "\n",
        "    def predict(self, X):\n",
        "        A = self.forward_propagation(X)\n",
        "        Y_hat = A[-1]\n",
        "        predictions = (Y_hat > self.threshold).astype(int)\n",
        "        return predictions, Y_hat\n",
        "\n",
        "    def accuracy(self, X, Y):\n",
        "        predictions, _ = self.predict(X)\n",
        "        accuracy = np.mean(predictions == Y)\n",
        "        return accuracy\n",
        "\n",
        "    def get_W_B(self):\n",
        "        return self.W, self.B\n"
      ],
      "metadata": {
        "id": "OOvFoIDXN9p-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize and train the model\n",
        "model = DeepNNONEOUT(DNN_Layers=[10, 5, 1], alpha=0.01, threshold=0.43)  # Example architecture\n",
        "model.train(x_train_padded, y_train_reshaped, iter_number=1000)\n",
        "\n",
        "# Compute accuracy on training set\n",
        "train_accuracy = model.accuracy(x_train_padded, y_train_reshaped)\n",
        "print(f\"Training accuracy: {train_accuracy * 100:.2f}%\")\n",
        "\n",
        "# Compute accuracy on test set\n",
        "test_accuracy = model.accuracy(x_test_padded, y_test_reshaped)\n",
        "print(f\"Test accuracy: {test_accuracy * 100:.2f}%\")\n",
        "\n",
        "predictions, y_hat = model.predict(x_test_padded)\n",
        "print(predictions)\n",
        "print(\"Actual\")\n",
        "print(y_test_reshaped)\n",
        "\n",
        "print(y_hat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXwQdQfkPc4F",
        "outputId": "4568a3d3-03b8-46fb-ecb8-c05be2269fe4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 50.54%\n",
            "Test accuracy: 50.03%\n",
            "[[1]\n",
            " [1]\n",
            " [0]\n",
            " ...\n",
            " [1]\n",
            " [0]\n",
            " [1]]\n",
            "Actual\n",
            "[[0]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [0]\n",
            " [0]\n",
            " [0]]\n",
            "[[0.46275377]\n",
            " [0.47110205]\n",
            " [0.32701022]\n",
            " ...\n",
            " [0.44247872]\n",
            " [0.42845375]\n",
            " [0.48383076]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from skimage import io, color, transform, feature"
      ],
      "metadata": {
        "id": "Qv9sWl6zRhoL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "model0 = models.Sequential([\n",
        "    layers.Dense(64, activation='sigmoid'),\n",
        "    layers.Dense(10, activation='sigmoid')\n",
        "])\n",
        "# Compile the model\n",
        "model0.compile(optimizer=tf.keras.optimizers.SGD(),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "18ay1AbERja7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model0.fit(x_train_padded, y_train_reshaped, epochs=10, batch_size=32, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHpLBY6iSZe_",
        "outputId": "d0ce2b8a-c756-49b0-86b1-fa1dba2ea357"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.8134 - accuracy: 0.5001 - val_loss: 0.7235 - val_accuracy: 0.4832\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 2s 2ms/step - loss: 0.7127 - accuracy: 0.5038 - val_loss: 0.7072 - val_accuracy: 0.5112\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.7029 - accuracy: 0.5049 - val_loss: 0.7010 - val_accuracy: 0.5026\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.6991 - accuracy: 0.5120 - val_loss: 0.6980 - val_accuracy: 0.4988\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.6970 - accuracy: 0.5142 - val_loss: 0.6965 - val_accuracy: 0.5044\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.6955 - accuracy: 0.5198 - val_loss: 0.6956 - val_accuracy: 0.4982\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 2s 2ms/step - loss: 0.6955 - accuracy: 0.5113 - val_loss: 0.6951 - val_accuracy: 0.5162\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.6946 - accuracy: 0.5128 - val_loss: 0.6945 - val_accuracy: 0.5112\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.6942 - accuracy: 0.5171 - val_loss: 0.6940 - val_accuracy: 0.5100\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.6942 - accuracy: 0.5181 - val_loss: 0.6928 - val_accuracy: 0.5246\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e387e9777c0>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test data\n",
        "test_loss, test_accuracy = model0.evaluate(xTest_normalized, y_test)\n",
        "# Format the test accuracy to display as 100 percent\n",
        "formatted_test_accuracy = \"{:.3%}\".format(test_accuracy)\n",
        "\n",
        "# Print the formatted test accuracy\n",
        "print(\"Test Accuracy:\", formatted_test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMl4rEThSXOo",
        "outputId": "9700bd84-de8f-4588-aab6-a85d325a06b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 2s 2ms/step - loss: 0.7037 - accuracy: 0.5051\n",
            "Test Accuracy: 50.508%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "it seems that the data needs more preprossing on it but the most important thing to me that my model works fine"
      ],
      "metadata": {
        "id": "tJ9oVDZ9SzhM"
      }
    }
  ]
}